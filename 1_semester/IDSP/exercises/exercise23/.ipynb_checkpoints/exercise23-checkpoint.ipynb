{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Classification with SciKit-Learn\n",
    "Classification is the process of predicting the class (also called target or label) of given data points. In more technical terms, classification predictive modeling is the task of approximating a mapping function from input variables (X) to discrete output variables (y).  \n",
    "Classification belongs to the category of supervised learning, meaning we know know the true class labels of the data we are using to train our model, that is both X and y are given in the data.\n",
    "\n",
    "For example, spam detection in email service providers can be identified as a classification problem. This is binary classification since there are only 2 classes: spam and not spam.  \n",
    "The model utilizes some training data to understand how given input variables relate to the class. In the email example case, known spam and non-spam emails have to be used as the training data. When the classifier is trained accurately, it can be used to label new unknown emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.0. Loading in the data\n",
    "In the folder for today's exercises, you have been supplied with the file `seeds.data` which contains the [Wheat Seeds Dataset](http://archive.ics.uci.edu/ml/datasets/seeds).  The data consists of 210 observations of seeds from 3 different varieties of wheat. The number of observations for each class is balanced. Each seed is described by 7 attributes and the class it belongs to:\n",
    "\n",
    "<img src=\"https://www.organicfoods.com.au/wp-content/uploads/2020/06/wheat-grain.png\" width=\"300\" align=\"right\">\n",
    "\n",
    "0. Surface area\n",
    "1. Perimeter\n",
    "2. Compactness\n",
    "3. Length of kernel\n",
    "4. Width of kernel\n",
    "5. Asymmetry coefficient.\n",
    "6. Length of kernel groove.\n",
    "7. Class: {1, 2, 3}\n",
    "\n",
    "**NB!** `seeds.data` is formatted as a tab-delimited data file and can be loaded using `np.loadtxt()` with default parameters.\n",
    "___\n",
    "`seeds.shape`  \n",
    "\\>\\> `(210, 8)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('seeds.data')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.1. Separate descriptive features and target feature\n",
    "Extract the 7 descriptive features into a matrix, `X`, and the target feature, class, into a column vector, `y`. \n",
    "\n",
    "Hint: Use numpy slicing\n",
    "___\n",
    "`X.shape`  \n",
    "\\>\\> `(210, 7)`\n",
    "\n",
    "`y.shape`  \n",
    "\\>\\> `(210,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 7)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,:7]\n",
    "Y = data[:,-1]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data and testing data\n",
    "To assess your model’s performance later, you will also need to divide the data set into two parts: a training set and a test set. The first is used to train the model, while the second is used to evaluate the trained model.\n",
    "\n",
    "The most common splitting choice is to take 70 % of your original data set as the training set, while the 30 % that remains will compose the test set. \n",
    "\n",
    "It is often a good idea to shuffle your data prior to splitting, to ensure that all classes are somewhat equally represented in both the train and test data. You’ll probably recognize, that shuffling has some randomness to it, so you should seed your shuffles to guarantee that your split data will always look the same. That is particularly handy if you want reproducible results.\n",
    "\n",
    "\n",
    "### 23.2. Split your data into a training set and a test set\n",
    "Use the `train_test_split` method from scikit-learn to split your data, with the test_size set to 0.3, and the random_state set to 3 (or another number you think is cool).\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "___\n",
    "`X_train.shape`  \n",
    "\\>\\> `(147, 7)`\n",
    "\n",
    "`y_test.shape`  \n",
    "\\>\\> `(63,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 7)\n",
      "(63, 7)\n",
      "(210, 7)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.1. Make a NaiveBayes classifier object and fit it to your training data\n",
    "Now, we finally get to make our machine learning model! Make a `GaussianNB()` object, and apply the `fit` method to the object to train the model to your training data.\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.5. Use your Naive Bayes Classifier to (re-)predict the labels for the training data\n",
    "Let's make our first prediction using our model. You will use the `predict` method on your classifier object and feed it your training data. So we're making a prediction for the data that the model already knows, so that we can see how accurately we modelled/learned the training data.\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "136\n",
      "Probability of guessing right is 92.51700680272108 %\n"
     ]
    }
   ],
   "source": [
    "guessed = clf.predict(X_train)\n",
    "#print(guessed) # these are the guessed classes\n",
    "#print(Y_train) #these are the real classes\n",
    "\n",
    "guessed == Y_train\n",
    "print(len(Y_train))\n",
    "print(len(Y_train[guessed == Y_train]))# DAMN THAT IS FUCKING AMAZING I WAS ABLE TO GUESS ALMOST ALL OF THEM\n",
    "\n",
    "probability = (len(Y_train[guessed == Y_train])/len(Y_train))*100 # probability of guessing right\n",
    "print('Probability of guessing right is', probability, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.6. Measure the accuracy of your model for the training data\n",
    "Use the `accuracy_score` method, and feed it your true labels for training data and your predicted labels.\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.51700680272108"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_train,guessed)\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.7. Repeat the two prior steps for the testing data\n",
    "Use your classifier object to make a prediction of the labels of the test data, and calculate the accuracy score by comparing the resulting labels to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of guessing right is 92.51700680272108 %\n"
     ]
    }
   ],
   "source": [
    "print('Probability of guessing right is', probability, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "### 23.8. Make a Random Forest Classifier and train it on your training data\n",
    "Make a `RandomForestClassifier()` object and train it on your training data using the `fit` method.\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier()\n",
    "clf2.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.9. Check the accuracy of your model on both the training and testing data\n",
    "Use the `predict` method on your classifier object to get both the predicted labels for the known training data and the unseen test data.\n",
    "\n",
    "Calculate the accuracy of your predictions using the `accuracy_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.873015873015873\n"
     ]
    }
   ],
   "source": [
    "guessedTrain = clf2.predict(X_train)\n",
    "guessedTest = clf2.predict(X_test)\n",
    "\n",
    "accuracyForTrain = accuracy_score(Y_train, guessedTrain)\n",
    "accuracyForTest = accuracy_score(Y_test, guessedTest)\n",
    "print(accuracyForTrain)\n",
    "print(accuracyForTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Play around with hyperparameters\n",
    "The classifiers we have used today were both made with scikit-learn's default parameters. This will very seldom be the optimal parameters for your task.  \n",
    "Make a new RandomForestClassifier object, but this time try changing some of the hyperparameters. Fit the classifier to your data, and see how the accuracy of your model changes on train and test data.\n",
    "\n",
    "The list of possible parameters can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
